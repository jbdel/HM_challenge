{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small interactive script to preprocess the inputs:\n",
    "1) Load the image information at the output of a Faster R-CNN\n",
    "2) Retrieve the image features\n",
    "3) Encode the texts using a pretrained Bert Tokenizer\n",
    "4) save everything in pickle files\n",
    "\n",
    "The image information is obtained from the output of the fc6 of a pretrained Faster R-CNN with a ResNeXt-152 backbone. They can be downloaded at https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz. They are downloaded in the lmdb format. In the corresponding directory, the image information is stored as keys-values, where the keys correspond to the id numbers of the images and the values are dictionnaries containing the following information: \"feature_path\", \"features\" (N=100, 2048), \"image_height\", \"image_width\", \"num_boxes\" (N,), \"objects\"(N,), \"cls_prob\" (N, 1601), \"bbox\" (100, 4).\n",
    "\n",
    "We only keep the image features. Then, we append the features to the Pandas DataFrames obtained from the .json data files (train, dev and test data). \n",
    "\n",
    "Then, we use a pretrained BERT Tokenizer to encode the texts. The text encodings are also appended to the Pandas DataFrames. They correspond to dictionnaries with the following information: \"input_tokens\" (max_seq_length=128,), \"input_ids\" (max_seq_length=128,), \"segment_ids\" (max_seq_length=128,), \"input_mask\" (max_seq_length=128,)\n",
    "\n",
    "Finally, we save the resulting DataFrames in pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdb_dir = '/Users/guillaumevalette/Desktop/HMDataset/detectron.lmdb/'\n",
    "\n",
    "train_path = '/Users/guillaumevalette/Desktop/HM_challenge/HMDataset/train.jsonl'\n",
    "dev_path = '/Users/guillaumevalette/Desktop/HM_challenge/HMDataset/dev.jsonl'\n",
    "test_path = '/Users/guillaumevalette/Desktop/HM_challenge/HMDataset/test.jsonl'\n",
    "\n",
    "train_data = '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/train_data'\n",
    "dev_data = '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/dev_data'\n",
    "test_data = '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_id_to_img_features(db_dir, img_id):\n",
    "    \"\"\" Utils function to retrieve an image features from its id.\"\"\"\n",
    "    # open lmdb environment\n",
    "    env_db = lmdb.open(path=db_dir, subdir=True, readonly=True, readahead=False)\n",
    "\n",
    "    # start transaction\n",
    "    txn = env_db.begin()\n",
    "    \n",
    "    # convert img_id to proper byte string for keys in database\n",
    "    id_str = str(img_id)\n",
    "    if len(id_str) < 5:\n",
    "        id_str = '0' + id_str\n",
    "    assert len(id_str) == 5\n",
    "    \n",
    "    # retreive value in database (in pickle format) associated to id_str\n",
    "    value = txn.get(id_str.encode()) \n",
    "    img_info = pickle.loads(value)\n",
    "\n",
    "    # reteive image features only\n",
    "    img_feat = img_info[\"features\"]\n",
    "\n",
    "    # close lmdb environment\n",
    "    env_db.close()\n",
    "\n",
    "    return img_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [train_path, dev_path, test_path]\n",
    "file_datas = [train_data, dev_data, test_data]\n",
    "\n",
    "for file_path, file_data in zip(file_paths, file_datas):\n",
    "    # create dataframe from .json data file\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    df.rename(columns={'img': 'img_name'}, inplace=True)\n",
    "\n",
    "    # append \"features\" column \n",
    "    df['features'] = df['id'].map(lambda img_id: \n",
    "                                   img_id_to_img_features(lmdb_dir, img_id))\n",
    "    \n",
    "    # save to pickle format\n",
    "    df.to_pickle(file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the above works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      id       img_name  label  \\\n0  42953  img/42953.png      0   \n1  23058  img/23058.png      0   \n2  13894  img/13894.png      0   \n3  37408  img/37408.png      0   \n4  82403  img/82403.png      0   \n\n                                                text  \\\n0   its their character not their color that matters   \n1  don't be afraid to love again everyone is not ...   \n2                           putting bows on your pet   \n3  i love everything and everybody! except for sq...   \n4  everybody loves chocolate chip cookies, even h...   \n\n                                            features  \n0  [[0.0, 0.0, 0.0, 0.0, 9.599549, 2.1708376, 13....  \n1  [[0.0, 0.0, 0.0, 0.0, 12.636864, 0.0, 7.682766...  \n2  [[0.0, 0.0, 0.0, 0.83242446, 5.372245, 2.75794...  \n3  [[0.0, 0.0, 0.0, 0.0, 11.302303, 0.0, 0.0, 0.0...  \n4  [[1.1141618, 0.0, 0.7985689, 0.0, 17.840979, 0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img_name</th>\n      <th>label</th>\n      <th>text</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42953</td>\n      <td>img/42953.png</td>\n      <td>0</td>\n      <td>its their character not their color that matters</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 9.599549, 2.1708376, 13....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23058</td>\n      <td>img/23058.png</td>\n      <td>0</td>\n      <td>don't be afraid to love again everyone is not ...</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 12.636864, 0.0, 7.682766...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13894</td>\n      <td>img/13894.png</td>\n      <td>0</td>\n      <td>putting bows on your pet</td>\n      <td>[[0.0, 0.0, 0.0, 0.83242446, 5.372245, 2.75794...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37408</td>\n      <td>img/37408.png</td>\n      <td>0</td>\n      <td>i love everything and everybody! except for sq...</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 11.302303, 0.0, 0.0, 0.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82403</td>\n      <td>img/82403.png</td>\n      <td>0</td>\n      <td>everybody loves chocolate chip cookies, even h...</td>\n      <td>[[1.1141618, 0.0, 0.7985689, 0.0, 17.840979, 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "train_df[\"label\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "type(train_df[\"features\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n         0.       ],\n       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  1.0427783,\n         0.       ],\n       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n         0.       ],\n       ...,\n       [ 7.8925724,  0.       ,  1.5643792, ...,  0.       ,  6.162105 ,\n         0.       ],\n       [ 0.       ,  0.       ,  4.50093  , ...,  0.       ,  0.       ,\n         0.       ],\n       [14.124166 ,  0.       ,  0.       , ...,  4.5912385,  0.       ,\n         0.       ]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "train_df[\"features\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0428,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 7.8926,  0.0000,  1.5644,  ...,  0.0000,  6.1621,  0.0000],\n        [ 0.0000,  0.0000,  4.5009,  ...,  0.0000,  0.0000,  0.0000],\n        [14.1242,  0.0000,  0.0000,  ...,  4.5912,  0.0000,  0.0000]])"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "torch.tensor(train_df[\"features\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_df[\"features\"]:\n",
    "    if item.shape != (100, 2048):\n",
    "        print('problem')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.randint(low=0, high=8500, size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id in img_id: \n",
    "    id_str = str(id)\n",
    "    if len(id_str) < 5:\n",
    "        id_str = '0' + id_str\n",
    "    env_db = lmdb.open(path=lmdb_dir, subdir=True, readonly=True, readahead=False)\n",
    "    txn = env_db.begin()\n",
    "    value = txn.get(id_str.encode()) \n",
    "    img_info = pickle.loads(value)\n",
    "    img_feat = img_info[\"features\"]\n",
    "    env_db.close()\n",
    "\n",
    "    if not np.array_equal(img_feat, train_df.loc[train_df[\"id\"] == id].iloc[0][\"features\"]):\n",
    "        print('problem')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit1b963fb927de4272acc391caa687587d",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}