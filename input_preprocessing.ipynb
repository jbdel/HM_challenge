{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small interactive script to preprocess the inputs:\n",
    "1) Load the image information at the output of a Faster R-CNN 2) Retrieve the image features 3) Encode the texts using a pretrained Bert Tokenizer 4) Save everything in pickle files\n",
    "\n",
    "The image information is obtained from the output of the fc6 of a pretrained Faster R-CNN with a ResNeXt-152 backbone. They can be downloaded at https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz. They are downloaded in the lmdb format. In the corresponding directory, the image information is stored as keys-values, where the keys correspond to the id numbers of the images and the values are dictionnaries containing the following information: \"feature_path\", \"features\" (N=100, 2048), \"image_height\", \"image_width\", \"num_boxes\" (N,), \"objects\"(N,), \"cls_prob\" (N, 1601), \"bbox\" (100, 4).\n",
    "\n",
    "We only keep the image features. Then, we append the features to the Pandas DataFrames obtained from the .json data files (train, dev and test data).\n",
    "\n",
    "Then, we use a pretrained BERT Tokenizer to encode the texts. The text encodings are also appended to the Pandas DataFrames. They correspond to dictionnaries with the following information: \"input_tokens\" (max_seq_length=128,), \"input_ids\" (max_seq_length=128,), \"segment_ids\" (max_seq_length=128,), \"input_mask\" (max_seq_length=128,)\n",
    "\n",
    "Finally, we save the resulting DataFrames in pickle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processors.bert_processor import bert_encoder\n",
    "from processors.img_processor import img_features_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdb_dir = '/Users/guillaumevalette/Desktop/HMDataset/detectron.lmdb/'\n",
    "\n",
    "train_path = '/Users/guillaumevalette/Desktop/HM_challenge/data/train.jsonl'\n",
    "dev_path = '/Users/guillaumevalette/Desktop/HM_challenge/data/dev.jsonl'\n",
    "test_path = '/Users/guillaumevalette/Desktop/HM_challenge/data/test.jsonl'\n",
    "\n",
    "train_data = '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/train_data'\n",
    "dev_data = '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/dev_data'\n",
    "test_data = '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/train_data'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b06ecdc14eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# save to pickle format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2723\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m         \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m     def to_clipboard(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/guillaumevalette/Desktop/HM_challenge/data/VisualBert/train_data'"
     ]
    }
   ],
   "source": [
    "file_paths = [train_path, dev_path, test_path]\n",
    "file_datas = [train_data, dev_data, test_data]\n",
    "\n",
    "for file_path, file_data in zip(file_paths, file_datas):\n",
    "    # create dataframe from .json data file\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    df.rename(columns={'img': 'img_name'}, inplace=True)\n",
    "\n",
    "    # append \"img_features\" column \n",
    "    df['img_features'] = df['id'].map(lambda img_id: img_features_loader(lmdb_dir, img_id))\n",
    "    \n",
    "    # append \"text_encoding\" column\n",
    "    df['text_encoding'] = df['text'].map(lambda seq: bert_encoder(seq))\n",
    "    \n",
    "    # save to pickle format\n",
    "    df.to_pickle(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the above works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      id       img_name  label  \\\n0  42953  img/42953.png      0   \n1  23058  img/23058.png      0   \n2  13894  img/13894.png      0   \n3  37408  img/37408.png      0   \n4  82403  img/82403.png      0   \n\n                                                text  \\\n0   its their character not their color that matters   \n1  don't be afraid to love again everyone is not ...   \n2                           putting bows on your pet   \n3  i love everything and everybody! except for sq...   \n4  everybody loves chocolate chip cookies, even h...   \n\n                                        img_features  \\\n0  [[0.0, 0.0, 0.0, 0.0, 9.599549, 2.1708376, 13....   \n1  [[0.0, 0.0, 0.0, 0.0, 12.636864, 0.0, 7.682766...   \n2  [[0.0, 0.0, 0.0, 0.83242446, 5.372245, 2.75794...   \n3  [[0.0, 0.0, 0.0, 0.0, 11.302303, 0.0, 0.0, 0.0...   \n4  [[1.1141618, 0.0, 0.7985689, 0.0, 17.840979, 0...   \n\n                                       text_encoding  \n0  {'input_tokens': ['its', 'their', 'character',...  \n1  {'input_tokens': ['don', ''', 't', 'be', 'afra...  \n2  {'input_tokens': ['putting', 'bows', 'on', 'yo...  \n3  {'input_tokens': ['i', 'love', 'everything', '...  \n4  {'input_tokens': ['everybody', 'loves', 'choco...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img_name</th>\n      <th>label</th>\n      <th>text</th>\n      <th>img_features</th>\n      <th>text_encoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>42953</td>\n      <td>img/42953.png</td>\n      <td>0</td>\n      <td>its their character not their color that matters</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 9.599549, 2.1708376, 13....</td>\n      <td>{'input_tokens': ['its', 'their', 'character',...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23058</td>\n      <td>img/23058.png</td>\n      <td>0</td>\n      <td>don't be afraid to love again everyone is not ...</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 12.636864, 0.0, 7.682766...</td>\n      <td>{'input_tokens': ['don', ''', 't', 'be', 'afra...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13894</td>\n      <td>img/13894.png</td>\n      <td>0</td>\n      <td>putting bows on your pet</td>\n      <td>[[0.0, 0.0, 0.0, 0.83242446, 5.372245, 2.75794...</td>\n      <td>{'input_tokens': ['putting', 'bows', 'on', 'yo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37408</td>\n      <td>img/37408.png</td>\n      <td>0</td>\n      <td>i love everything and everybody! except for sq...</td>\n      <td>[[0.0, 0.0, 0.0, 0.0, 11.302303, 0.0, 0.0, 0.0...</td>\n      <td>{'input_tokens': ['i', 'love', 'everything', '...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82403</td>\n      <td>img/82403.png</td>\n      <td>0</td>\n      <td>everybody loves chocolate chip cookies, even h...</td>\n      <td>[[1.1141618, 0.0, 0.7985689, 0.0, 17.840979, 0...</td>\n      <td>{'input_tokens': ['everybody', 'loves', 'choco...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.        ,  1.9127843 ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  1.5968409 ,  0.        , ...,  0.        ,\n         0.        ,  0.42826056],\n       ...,\n       [10.182184  ,  0.        ,  0.        , ...,  0.        ,\n         7.8023977 ,  0.        ],\n       [ 0.09641957,  0.        ,  4.907559  , ...,  0.        ,\n         6.407262  ,  0.        ],\n       [ 0.        ,  0.        , 13.499453  , ...,  0.        ,\n         2.0245812 ,  0.        ]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_df[\"img_features\"][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 2048)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_df[\"img_features\"][42].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'that chiken is so black no one is going to eat it'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train_df[\"text\"][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'input_tokens': ['that',\n  'chi',\n  '##ken',\n  'is',\n  'so',\n  'black',\n  'no',\n  'one',\n  'is',\n  'going',\n  'to',\n  'eat',\n  'it'],\n 'input_ids': array([ 101, 2008, 9610, 7520, 2003, 2061, 2304, 2053, 2028, 2003, 2183,\n        2000, 4521, 2009,  102,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0], dtype=uint64),\n 'segment_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n 'input_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)}"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_df[\"text_encoding\"][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_df[\"img_features\"]:\n",
    "    if item.shape != (100, 2048):\n",
    "        print('problem')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.randint(low=0, high=8500, size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for id in ids:\n",
    "    img_id = train_df[\"id\"][id]\n",
    "    id_str = str(img_id)\n",
    "    if len(id_str) < 5:\n",
    "        id_str = '0' + id_str\n",
    "    env_db = lmdb.open(path=lmdb_dir, subdir=True, readonly=True, readahead=False)\n",
    "    txn = env_db.begin()\n",
    "    value = txn.get(id_str.encode()) \n",
    "    img_info = pickle.loads(value)\n",
    "    img_feat = img_info[\"features\"]\n",
    "    env_db.close()\n",
    "\n",
    "    if not np.array_equal(img_feat, train_df.loc[train_df[\"id\"] == img_id].iloc[0][\"img_features\"]):\n",
    "        print('problem')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'[CLS] that chiken is so black no one is going to eat it [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "tokenizer.decode(train_df[\"text_encoding\"][42][\"input_ids\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit1b963fb927de4272acc391caa687587d",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}